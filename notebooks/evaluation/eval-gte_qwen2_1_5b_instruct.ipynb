{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9428bcf-62b4-4f23-8793-57dd8cccc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacado de la documentación, yo no lo he ejecutado.\n",
    "# %pip install llama-index-llms-openai llama-index-embeddings-openai\n",
    "\n",
    "# estos son los módulos que tengo instalados\n",
    "# pip install llama-index\n",
    "# pip install llama-index-embeddings-huggingface\n",
    "# pip install llama-index-llms-ollama\n",
    "# pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8dee1ca-879e-4ae8-8efc-08d07f2a695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a14b3e-dceb-417d-8813-c88cb88a0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"TU KEY\"\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2f4f7f-1c0b-4812-b88f-c0a0ef51c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Response\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    GuidelineEvaluator,\n",
    "    SemanticSimilarityEvaluator\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec67b1ad-66b2-4820-8397-3099989578b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-3.5-turbo\n",
    "gpt3_5 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "faithfulness_gpt3_5 = FaithfulnessEvaluator(llm=gpt3_5)\n",
    "relevancy_gpt3_5 = RelevancyEvaluator(llm=gpt3_5)\n",
    "correctness_gpt3_5 = CorrectnessEvaluator(llm=gpt3_5)\n",
    "semantic = SemanticSimilarityEvaluator()  # coge el modelo de embedings de settings si no se le pasa ninguno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56fcc41-9a74-4fe1-a541-5c338e8209df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6290bb68b346473c9da07f3bcb176bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb7be8489314033b9daeeda8fb7dea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/284 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3df295395e4031b8340bb6b5e5370f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/145k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc6f3714ff944dfb84a0e22c812e75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/55.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691d036d1401400f936059dcf0ff4d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/879 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17748f8fe02c45e597e73d0484d78daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89722426308d4a7682c34715e501c1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf69f05228e49289b44d9dc7c8a454a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f7954e5b7e4cc2ac08e31626857d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01d13b256e34b96b75bbe1aff33bf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96be90ca81294862919f72cfe3b86092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bf349b0b2846c38ad0fc770103f7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b1128339a4403ead100140a47ec5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6ef417dc77436f917031ead3bcf480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bbdb0847ab4499a97ba3fca0c6ed12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d015614ae849718985a8b3387b3d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913272cd9adf465fa644c5b834ff785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creo el modelo de embeddings que quiero probar\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40846c46-16e4-40ab-9453-fb966c6a4221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alibaba-NLP/gte-Qwen2-1.5B-instruct\n"
     ]
    }
   ],
   "source": [
    "print(Settings.embed_model.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a222d30-516d-4a02-876a-5cf9698f5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquí crear el modelo que quieras evaluar\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3_1_sauerkraut\", request_timeout=360.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f068f61-6377-4c95-8643-e74854884cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinar_diccionarios(dict1, dict2):\n",
    "    resultado = {}\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            # Combina los arrays de ambas claves en un solo array\n",
    "            resultado[key] = dict1[key] + dict2[key]\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604b1d27-9fbe-41e2-bd7a-0aed06f3a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# he modificado la del ejemplo para que use result.score en vez de result.passing. en algunos tipos de evaluación sale un resultado más preciso\n",
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    sum_score = 0\n",
    "    count = 0\n",
    "    for result in results:\n",
    "        if result.score is not None:  # Verifica si score no es None\n",
    "            sum_score += result.score\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        print(f\"{key} Score: No valid scores\")\n",
    "        return None\n",
    "    score = sum_score / count\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29194fda-1572-48e6-880a-a6623d6b53a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of correctcness results: 20\n",
      "results of dataset paul_graham of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 1.0\n",
      "relevancy Score: 0.9\n",
      "correctness Score: 3.861111111111111\n",
      "semantic Score: 0.9411313196366148\n",
      "length of correctcness results: 40\n",
      "results of dataset Blockchain of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 0.95\n",
      "relevancy Score: 0.85\n",
      "correctness Score: 3.9\n",
      "semantic Score: 0.9374627925578796\n",
      "length of correctcness results: 60\n",
      "results of dataset Alexnet of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 0.95\n",
      "relevancy Score: 0.9\n",
      "correctness Score: 4.078947368421052\n",
      "semantic Score: 0.9424337046168236\n",
      "length of correctcness results: 80\n",
      "results of dataset Covid of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 0.95\n",
      "relevancy Score: 0.85\n",
      "correctness Score: 4.055555555555555\n",
      "semantic Score: 0.9380275707933338\n",
      "length of correctcness results: 100\n",
      "results of dataset Llama2Paper of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 0.95\n",
      "relevancy Score: 0.95\n",
      "correctness Score: 3.925\n",
      "semantic Score: 0.9392795312923907\n",
      "total results of all datasets of embeddings model: Alibaba-NLP/gte-Qwen2-1.5B-instruct\n",
      "faithfulness Score: 0.96\n",
      "relevancy Score: 0.89\n",
      "correctness Score: 3.963157894736842\n",
      "semantic Score: 0.9396669837794086\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llama_dataset import download_llama_dataset, LabelledRagDataset\n",
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "datasets = [\"paul_graham\", \"Blockchain\", \"Alexnet\", \"Covid\", \"Llama2Paper\"]\n",
    "total_results = {\"correctness\": [], \"faithfulness\": [], \"relevancy\": [], \"semantic\": []}\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    path_dataset = f\"./eval_data/rag_data/{datasets[0]}/rag_dataset.json\"\n",
    "    path_documents = f\"./eval_data/rag_data/{datasets[0]}/source_files\"\n",
    "    rag_dataset = LabelledRagDataset.from_json(path_dataset)\n",
    "    documents = SimpleDirectoryReader(input_dir=path_documents).load_data()\n",
    "\n",
    "    rag_dataset_pandas = rag_dataset.to_pandas()\n",
    "    queries = rag_dataset_pandas[\"query\"]\n",
    "    reference_answers = rag_dataset_pandas[\"reference_answer\"]\n",
    "    \n",
    "    queries = queries[:20]\n",
    "    reference_answers = reference_answers[:20].to_list()\n",
    "\n",
    "    splitter = SentenceSplitter(chunk_size=512)\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, transformations=[splitter]\n",
    "    )\n",
    "\n",
    "    # ponemos todos los evaluadores que queremos usar aquí.\n",
    "    runner = BatchEvalRunner(\n",
    "        {\"correctness\": correctness_gpt3_5,\n",
    "         \"faithfulness\": faithfulness_gpt3_5,\n",
    "         \"relevancy\": relevancy_gpt3_5,\n",
    "         \"semantic\": semantic},\n",
    "        workers=8,\n",
    "    )\n",
    "    \n",
    "    # he corregido una cosa de aquí del ejemplo, que no estaba (llm=llm), supongo que por error.\n",
    "    eval_results = await runner.aevaluate_queries(\n",
    "        vector_index.as_query_engine(llm=llm),\n",
    "        queries=queries,\n",
    "        reference=reference_answers,\n",
    "    )\n",
    "    \n",
    "    total_results = combinar_diccionarios(total_results, eval_results)\n",
    "    print(f\"length of correctcness results: {len(total_results[\"correctness\"])}\")\n",
    "\n",
    "    print(f\"results of dataset {dataset_name} of embeddings model: {Settings.embed_model.model_name}\")\n",
    "    score_faithfulness = get_eval_results(\"faithfulness\", eval_results)\n",
    "    score_relevancy = get_eval_results(\"relevancy\", eval_results)\n",
    "    score_correctness = get_eval_results(\"correctness\", eval_results)\n",
    "    score_semantic = get_eval_results(\"semantic\", eval_results)\n",
    "\n",
    "print(f\"total results of all datasets of embeddings model: {Settings.embed_model.model_name}\")\n",
    "score_faithfulness = get_eval_results(\"faithfulness\", total_results)\n",
    "score_relevancy = get_eval_results(\"relevancy\", total_results)\n",
    "score_correctness = get_eval_results(\"correctness\", total_results)\n",
    "score_semantic = get_eval_results(\"semantic\", total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce1c4d1-d3bd-4faa-bfe3-116501df2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['correctness', 'faithfulness', 'relevancy', 'semantic'])\n",
      "dict_keys(['query', 'contexts', 'response', 'passing', 'feedback', 'score', 'pairwise_source', 'invalid_result', 'invalid_reason'])\n",
      "True\n",
      "The author's first experience with a computer was on an IBM 1401, which was located in the basement of his junior high school. He had to type programs on punch cards and then stack them in the card reader to load the program into memory for execution. The language he used was an early version of Fortran.\n",
      "\n",
      "The author faced challenges using this computer due to its limited capabilities. He didn't have any data stored on punched cards, which meant that most tasks required input from these cards. Without such data, his options were restricted. Additionally, he lacked sufficient mathematical knowledge to write more complex programs or engage in interesting calculations like approximating pi. This led to a lack of memorable programs and experiences during this time.\n",
      "\n",
      "One of the few notable events was when one of his programs failed to terminate, which was both a technical and social issue due to the machine's limitations in handling non-terminating tasks without time-sharing capabilities.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(eval_results.keys())\n",
    "\n",
    "print(eval_results[\"correctness\"][0].dict().keys())\n",
    "\n",
    "print(eval_results[\"correctness\"][0].passing)\n",
    "print(eval_results[\"correctness\"][0].response)\n",
    "print(eval_results[\"correctness\"][0].contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e8f924-9e46-4b80-b4c1-3c352209567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvaluationResult(query='In the essay, the author mentions his early experiences with programming. Describe the first computer he used for programming, the language he used, and the challenges he faced.', contexts=None, response=\"The author's first experience with a computer was on an IBM 1401, which was located in the basement of his junior high school. He had to type programs on punch cards and then stack them in the card reader to load the program into memory for execution. The language he used was an early version of Fortran.\\n\\nThe author faced challenges using this computer due to its limited capabilities. He didn't have any data stored on punched cards, which meant that most tasks required input from these cards. Without such data, his options were restricted. Additionally, he lacked sufficient mathematical knowledge to write more complex programs or engage in interesting calculations like approximating pi. This led to a lack of memorable programs and experiences during this time.\\n\\nOne of the few notable events was when one of his programs failed to terminate, which was both a technical and social issue due to the machine's limitations in handling non-terminating tasks without time-sharing capabilities.\", passing=True, feedback='The generated answer provides relevant information about the first computer the author used for programming (IBM 1401), the programming language (Fortran), and the challenges faced. It accurately describes the process of using punch cards for input and the limitations faced due to the lack of data stored on punched cards. The only minor discrepancy is the mention of the location of the computer (basement of junior high school) which was not specified in the user query but does not significantly impact the overall correctness of the answer.', score=4.5, pairwise_source=None, invalid_result=False, invalid_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"correctness\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876cabe1-3c56-4cd9-8da6-b051537a660a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b378de-c3af-4e8d-9b43-9b110efaa550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af3f2e-4bf5-4acb-8d7c-0e2289aaecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a478b-b060-4288-b479-dba8fa694680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bc6dc-7a82-48a9-94f5-da7b0d906da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
