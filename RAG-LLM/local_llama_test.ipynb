{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama_index\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Verificar si la GPU está disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmsol\\anaconda3\\envs\\tfm_integracion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Aug  9 12:10:23 2024\n",
    "\n",
    "@author: eduardocarreroyubero\n",
    "\"\"\"\n",
    "\n",
    "# !pip install llama-index\n",
    "# !pip install llama-index-embeddings-huggingface\n",
    "# !pip install llama-index-llms-ollama\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "api_key = \"PONER LA TUYA\"\n",
    "\n",
    "documents = SimpleDirectoryReader(\"C:/Users/gmsol/Desktop/videodescargas/transcripciones\").load_data()\n",
    "\n",
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# ollama\n",
    "# importante: installar ollama y levantar el modelo que quieras usar por linea de comandos (https://github.com/ollama/ollama?tab=readme-ov-file)\n",
    "Settings.llm = Ollama(model=\"llama3.1\", request_timeout=360.0, device_map=device)\n",
    "# Settings.llm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(documents)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gmsol\\anaconda3\\envs\\tfm_integracion\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")\n",
    "\n",
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La situación es más compleja de lo que parece al principio. Si los leones formaran una cadena y la población se mantuviera estable en cada generación, tendrían que pasar más de 10 billones de generaciones para alcanzar el trillón de leoncitos, unos 100 billones de años. Sin embargo, el Sol ya se apagará en unos 5.000 millones de años.\n",
      "\n",
      "Pero, si los leones lograran comprimirse hasta formar un agujero negro y este se instalara en el interior del Sol, podrían vencer al Sol en unos 2.500 millones de años. Además, incluso si el agujero negro no fuera capaz de detener directamente al Sol, tendría una vida útil de aproximadamente 10 sextillones de años, lo que significa que podría seguir \"viviendo\" mucho después del final del Sol.\n",
      "\n",
      "Por tanto, en ambas escenarios los leones ganarían.\n"
     ]
    }
   ],
   "source": [
    "question = \"quien ganaria, leones o el sol? justifica tu respuesta\"\n",
    "prompt =f'''Tienes acceso a transcripciones de videos de youtube.\n",
    "            Se te hará una pregunta y debes responder basándote exclusivamente en la información proporcionada en las transcripciones. Si no puedes responder la pregunta utilizando estos datos, indica que la información no está disponible.\n",
    "\n",
    "            Responde de manera educada, estructurada y concisa cuando corresponda. Si la pregunta requiere una respuesta breve, sé claro y directo. Asegúrate de:\n",
    "\n",
    "            No inventar información adicional ni suponer nada que no esté claramente expresado en las transcripciones.\n",
    "            Responder solo utilizando la información proporcionada, sin hacer inferencias más allá del contenido.\n",
    "            Estructurar la respuesta de manera clara y fácil de entender.\n",
    "            Mantener un tono respetuoso y profesional en todo momento.\n",
    "            \n",
    "            PREGUNTA:\n",
    "            {question}\n",
    "            '''\n",
    "response = query_engine.query(question)\n",
    "print(response)\n",
    "# Se realizarán obras para mejorar y ampliar las infraestructuras hidráulicas en determinados municipios de las Illes Balears, incluyendo la mejora del tratamiento EDAR de Sant Lluís.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La conclusión es clara: el Sol ganaría sin problema. La energía necesaria para destruirlo es extremadamente alta y actualmente no existe tecnología ni recursos disponibles para lograr tal objetivo, incluso en un escenario hipotético donde los leones se lanzan a una velocidad cercana a la velocidad de la luz.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9fb38f49-1a4b-4c3a-bf16-2399cf8fab26': {'file_path': 'C:\\\\Users\\\\gmsol\\\\Desktop\\\\videodescargas\\\\transcripciones\\\\Cómo Podría 1 Trillón de Leones Ganarle al Sol NRAbqNtUgdUm4a.txt',\n",
       "  'file_name': 'Cómo Podría 1 Trillón de Leones Ganarle al Sol NRAbqNtUgdUm4a.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 11994,\n",
       "  'creation_date': '2024-08-31',\n",
       "  'last_modified_date': '2024-08-31'},\n",
       " 'e03e4da0-ed90-4013-be96-fc32f8deb317': {'file_path': 'C:\\\\Users\\\\gmsol\\\\Desktop\\\\videodescargas\\\\transcripciones\\\\Cómo Podría 1 Trillón de Leones Ganarle al Sol NRAbqNtUgdUm4a.txt',\n",
       "  'file_name': 'Cómo Podría 1 Trillón de Leones Ganarle al Sol NRAbqNtUgdUm4a.txt',\n",
       "  'file_type': 'text/plain',\n",
       "  'file_size': 11994,\n",
       "  'creation_date': '2024-08-31',\n",
       "  'last_modified_date': '2024-08-31'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
