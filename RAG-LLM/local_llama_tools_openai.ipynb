{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama_index\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-llms-ollama\n",
    "\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core import load_index_from_storage, StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import os\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools.query_engine import QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "directory_path = \"C:/Users/gmsol/Desktop/videodescargas/transcripciones\"\n",
    "transcripciones = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "# Define the pattern for allowed characters in filenames\n",
    "pattern = re.compile(r'^[a-zA-Z0-9_-]+$')\n",
    "\n",
    "# Function to sanitize filenames\n",
    "def sanitize_filename(filename):\n",
    "    return re.sub(r'[^a-zA-Z0-9_-]', '', filename)\n",
    "\n",
    "# Check and rename files if necessary\n",
    "for transcripcion in transcripciones:\n",
    "    filename = os.path.basename(transcripcion)\n",
    "    if not pattern.match(filename):\n",
    "        new_filename = sanitize_filename(filename)\n",
    "        old_path = os.path.join(directory_path, filename)\n",
    "        new_path = os.path.join(directory_path, new_filename)\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed '{filename}' to '{new_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Verificar si la GPU está disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crear una lista con los nombres de los ficheros en el directorio \"transcripciones\"\n",
    "\n",
    "\n",
    "docs={}\n",
    "for transcripcion in transcripciones:\n",
    "    docs[transcripcion] = SimpleDirectoryReader(\n",
    "        input_files=[f\"C:/Users/gmsol/Desktop/videodescargas/transcripciones/{transcripcion}\"],\n",
    "    ).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"C:/Users/gmsol/Desktop/videodescargas/transcripciones\").load_data()\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 docs\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(docs)} docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings.llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter()\n",
    "\n",
    "# Build agents dictionary\n",
    "agents = {}\n",
    "query_engines = {}\n",
    "\n",
    "# this is for the baseline\n",
    "all_nodes = []\n",
    "\n",
    "for idx, transcripcion in enumerate(transcripciones):\n",
    "    nodes = node_parser.get_nodes_from_documents(docs[transcripcion])\n",
    "    all_nodes.extend(nodes)\n",
    "\n",
    "    if not os.path.exists(f\"./indexes/{transcripcion}\"):\n",
    "        # build vector index\n",
    "        vector_index = VectorStoreIndex(nodes)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./indexes/{transcripcion}\"\n",
    "        )\n",
    "    else:\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./indexes/{transcripcion}\"),\n",
    "        )\n",
    "\n",
    "    # build summary index\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
    "    summary_query_engine = summary_index.as_query_engine(llm=Settings.llm)\n",
    "\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description=(\n",
    "                    \"Useful for questions related to specific aspects in relation to the topic:\"\n",
    "                    f\" {transcripcion}. \"\n",
    "                    \n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        QueryEngineTool(\n",
    "            query_engine=summary_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"summary_tool\",\n",
    "                description=(\n",
    "                    \"Useful for any requests that require a holistic summary\"\n",
    "                    f\" of EVERYTHING about {transcripcion}. For questions about\"\n",
    "                    \" more specific sections, please use the vector_tool.\"\n",
    "                    \n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    agent = ReActAgent.from_tools(\n",
    "    query_engine_tools, \n",
    "    verbose=True,\n",
    "    system_prompt=f\"\"\"\\\n",
    "        You are a specialized agent designed to answer queries about {transcripcion}.\n",
    "        You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
    "        \"\"\"\n",
    "    )\n",
    "    agents[transcripcion] = agent\n",
    "    query_engines[transcripcion] = vector_index.as_query_engine(\n",
    "        similarity_top_k=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_tools = []\n",
    "for transcripcion in transcripciones:\n",
    "    transcript_summary = (\n",
    "        f\"This content contains the transcription of a video called {transcripcion}. Use\"\n",
    "        f\" this tool if you want to answer any questions about {transcripcion}.\\n\"\n",
    "    )\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[transcripcion],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{transcripcion}\",\n",
    "            description=transcript_summary,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "\n",
    "top_agent = OpenAIAgent.from_tools(\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries about a video transcriptions.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Segun el doctor del sueño, que podemos hacer para dormir mejor?\n",
      "=== Calling Function ===\n",
      "Calling function: tool_UnaClaseconelDrdelSueotxt with args: {\"input\":\"Segun el doctor del sueño, que podemos hacer para dormir mejor?\"}\n",
      "\u001b[1;3;38;5;200mThought: The user is asking for advice on how to sleep better according to the sleep doctor in the text UnaClaseconelDrdelSueotxt. I should use a tool to help me answer the question.\n",
      "Action: vector_tool\n",
      "Action Input: {'input': 'Consejos para dormir mejor según el doctor del sueño en UnaClaseconelDrdelSueotxt'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Para dormir mejor según el doctor del sueño en \"Una Clase con el Dr. del Sueño\", se pueden seguir los siguientes consejos: evitar dormir boca arriba, optar por dormir de lado, realizar siestas cortas como complemento de una buena noche de sueño, desconectar antes de dormir mediante técnicas como la respiración o la meditación, y levantarse de la cama si no se logra conciliar el sueño para evitar asociaciones negativas con el lugar de descanso.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer the user's question without using any more tools.\n",
      "Answer: Según el doctor del sueño en \"Una Clase con el Dr. del Sueño\", para dormir mejor se recomienda evitar dormir boca arriba, optar por dormir de lado, realizar siestas cortas como complemento de una buena noche de sueño, desconectar antes de dormir mediante técnicas como la respiración o la meditación, y levantarse de la cama si no se logra conciliar el sueño para evitar asociaciones negativas con el lugar de descanso.\n",
      "\u001b[0mGot output: Según el doctor del sueño en \"Una Clase con el Dr. del Sueño\", para dormir mejor se recomienda evitar dormir boca arriba, optar por dormir de lado, realizar siestas cortas como complemento de una buena noche de sueño, desconectar antes de dormir mediante técnicas como la respiración o la meditación, y levantarse de la cama si no se logra conciliar el sueño para evitar asociaciones negativas con el lugar de descanso.\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"Segun el doctor del sueño, que podemos hacer para dormir mejor?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: De que habla el podcast del doctor del sueño\n",
      "=== Calling Function ===\n",
      "Calling function: tool_UnaClaseconelDrdelSueotxt with args: {\"input\":\"De que habla el podcast del doctor del sueño\"}\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Spanish. I need to use a tool to help me answer the question.\n",
      "Action: summary_tool\n",
      "Action Input: {'input': 'UnaClaseconelDrdelSueotxt'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The text delves into a conversation with a sleep expert covering various topics related to sleep, including the impact of light exposure on sleep quality, the importance of maintaining a consistent sleep routine, and the potential benefits of smart lighting solutions for mental health. The expert also touches on the effects of physical activity and sexual activity on sleep, emphasizing the significance of avoiding screen time before bedtime for better sleep quality.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: El podcast del Doctor del Sueño aborda diversos temas relacionados con el sueño, como el impacto de la exposición a la luz en la calidad del sueño, la importancia de mantener una rutina de sueño consistente y los posibles beneficios de las soluciones de iluminación inteligente para la salud mental. También se mencionan los efectos de la actividad física y la actividad sexual en el sueño, haciendo hincapié en la importancia de evitar el uso de pantallas antes de dormir para una mejor calidad de sueño.\n",
      "\u001b[0mGot output: El podcast del Doctor del Sueño aborda diversos temas relacionados con el sueño, como el impacto de la exposición a la luz en la calidad del sueño, la importancia de mantener una rutina de sueño consistente y los posibles beneficios de las soluciones de iluminación inteligente para la salud mental. También se mencionan los efectos de la actividad física y la actividad sexual en el sueño, haciendo hincapié en la importancia de evitar el uso de pantallas antes de dormir para una mejor calidad de sueño.\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"De que habla el podcast del doctor del sueño\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
