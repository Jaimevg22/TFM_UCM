{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9428bcf-62b4-4f23-8793-57dd8cccc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sacado de la documentación, yo no lo he ejecutado.\n",
    "# %pip install llama-index-llms-openai llama-index-embeddings-openai\n",
    "\n",
    "# estos son los módulos que tengo instalados\n",
    "# pip install llama-index\n",
    "# pip install llama-index-embeddings-huggingface\n",
    "# pip install llama-index-llms-ollama\n",
    "# pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8dee1ca-879e-4ae8-8efc-08d07f2a695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the same event-loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a14b3e-dceb-417d-8813-c88cb88a0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"TU KEY\"\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2f4f7f-1c0b-4812-b88f-c0a0ef51c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Response\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    "    GuidelineEvaluator,\n",
    "    SemanticSimilarityEvaluator\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec67b1ad-66b2-4820-8397-3099989578b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4\n",
    "# gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
    "gpt4 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "faithfulness_gpt4 = FaithfulnessEvaluator(llm=gpt4)\n",
    "relevancy_gpt4 = RelevancyEvaluator(llm=gpt4)\n",
    "correctness_gpt4 = CorrectnessEvaluator(llm=gpt4)\n",
    "semantic = SemanticSimilarityEvaluator()  # coge el modelo de embedings de settings si no se le pasa ninguno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "29194fda-1572-48e6-880a-a6623d6b53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import download_llama_dataset, LabelledRagDataset\n",
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/paul_graham/rag_dataset.json\")  # 44 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/paul_graham/source_files\").load_data()\n",
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/Blockchain/rag_dataset.json\")  # 58 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/Blockchain/source_files\").load_data()\n",
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/Alexnet/rag_dataset.json\")  # 160 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/Alexnet/source_files\").load_data()\n",
    "\n",
    "rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/Covid/rag_dataset.json\")  # 316 queries.\n",
    "documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/Covid/source_files\").load_data()\n",
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/Llama2Paper/rag_dataset.json\")  # 100 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/Llama2Paper/source_files\").load_data()\n",
    "\n",
    "\n",
    "# SE QUEDA PILLADO porque son muchos documentos creo\n",
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/FinanceBench/rag_dataset.json\")  # 98 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/FinanceBench/source_files\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f6178895-7d53-4544-b718-dade78664f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en el caso de que quisieramos generar un dataset de queries a raíz de los documentos\n",
    "\n",
    "# from llama_index.core.evaluation import DatasetGenerator\n",
    "\n",
    "# dataset_generator = DatasetGenerator.from_documents(documents, llm=llm)\n",
    "\n",
    "# qas = dataset_generator.generate_dataset_from_nodes(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ccecf35b-5015-41ae-8271-bb12d1f9a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rag_dataset = LabelledRagDataset.from_json(\"./eval_data/rag_data/FinanceBench/rag_dataset.json\")  # 98 queries.\n",
    "# documents = SimpleDirectoryReader(input_dir=\"./eval_data/rag_data/FinanceBench/source_files\").load_data()rag_dataset_pandas = rag_dataset.to_pandas()\n",
    "# queries = rag_dataset_pandas[\"query\"]\n",
    "# reference_answers = rag_dataset_pandas[\"reference_answer\"]\n",
    "# queries = queries[:20]\n",
    "# reference_answers = reference_answers[:20].to_list()# create vector index\n",
    "# splitter = SentenceSplitter(chunk_size=512)\n",
    "# vector_index = VectorStoreIndex.from_documents(\n",
    "#     documents, transformations=[splitter]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4514be2d-f4d7-412a-9c25-579659f175d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset_pandas = rag_dataset.to_pandas()\n",
    "queries = rag_dataset_pandas[\"query\"]\n",
    "reference_answers = rag_dataset_pandas[\"reference_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f2354064-76b7-4c70-a492-eaac60326a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este paso lo hago simplemente para reducir el tamaño del dataset,\n",
    "# para que no tarde mucho la evaluación cada vez que hago pruebas durante el desarrollo\n",
    "\n",
    "queries = queries[:20]\n",
    "reference_answers = reference_answers[:20].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "03118bbd-7262-4b8e-8179-62412de72c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(queries))\n",
    "print(len(reference_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "131489bc-6b14-4240-8f14-2ecf414c0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # aquí crear el modelo que quieras evaluar\n",
    "\n",
    "# llm = OpenAI(temperature=0.3, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "04af10b3-40ee-416b-896f-5e281a50b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install protobuf\n",
    "# !conda install conda-forge::triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7a222d30-516d-4a02-876a-5cf9698f5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquí crear el modelo que quieras evaluar\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"internlm2\", request_timeout=360.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d608c5e7-c1b9-4d85-9668-607d6471e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# embed_model.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "754e787e-fa3c-4813-a7f7-467f51886c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[splitter]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "62bf3b48-8fd0-43a8-a2fe-d11e6f556b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "# ponemos todos los evaluadores que queremos usar aquí.\n",
    "runner = BatchEvalRunner(\n",
    "    {\"correctness\": correctness_gpt4,\n",
    "     \"faithfulness\": faithfulness_gpt4,\n",
    "     \"relevancy\": relevancy_gpt4,\n",
    "     \"semantic\": semantic},\n",
    "    workers=8,\n",
    ")\n",
    "\n",
    "# he corregido una cosa de aquí del ejemplo, que no estaba (llm=llm), supongo que por error.\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    vector_index.as_query_engine(llm=llm),\n",
    "    queries=queries,\n",
    "    reference=reference_answers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f6e36018-9dd3-4e2a-98c4-d505e95a7ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# print(eval_results)\n",
    "print(len(eval_results[\"correctness\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9809f5b6-8031-4e2a-a594-d15d0742cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_results = eval_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f068f61-6377-4c95-8643-e74854884cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinar_diccionarios(dict1, dict2):\n",
    "    resultado = {}\n",
    "    for key in dict1:\n",
    "        if key in dict2:\n",
    "            # Combina los arrays de ambas claves en un solo array\n",
    "            resultado[key] = dict1[key] + dict2[key]\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "81d4895c-4620-4ae8-a266-a6819c2892f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "total_results = combinar_diccionarios(total_results, eval_results)\n",
    "print(len(total_results[\"correctness\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "50ea37ae-56ed-4aab-9684-dfc96fc0a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6ce1c4d1-d3bd-4faa-bfe3-116501df2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['correctness', 'faithfulness', 'relevancy', 'semantic'])\n",
      "dict_keys(['query', 'contexts', 'response', 'passing', 'feedback', 'score', 'pairwise_source', 'invalid_result', 'invalid_reason'])\n",
      "True\n",
      "The article details several potential early signs of Covid-19 infection. These include sore throat, fever, chills, muscle aches, gastrointestinal disturbances such as diarrhea and nausea, and changes in sense of smell or taste. Some individuals may experience painful red and purple lesions on their fingers and toes, which are referred to as \"Covid toe.\" Symptoms can vary widely among different people; some might not show many symptoms at all.\n",
      "\n",
      "More serious cases have been associated with inflammation and organ damage even without difficulty breathing. There has also been a noted incidence of dangerous blood clots, strokes, and brain impairments in severe Covid-19 infections.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(eval_results.keys())\n",
    "\n",
    "print(eval_results[\"correctness\"][0].dict().keys())\n",
    "\n",
    "print(eval_results[\"correctness\"][0].passing)\n",
    "print(eval_results[\"correctness\"][0].response)\n",
    "print(eval_results[\"correctness\"][0].contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d78cadff-b42a-4deb-ad85-a437eb2d3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# he modificado la del ejemplo para que use result.score en vez de result.passing. en algunos tipos de evaluación sale un resultado más preciso\n",
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    sum_score = 0\n",
    "    count = 0\n",
    "    for result in results:\n",
    "        if result.score is not None:  # Verifica si score no es None\n",
    "            sum_score += result.score\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        print(f\"{key} Score: No valid scores\")\n",
    "        return None\n",
    "    score = sum_score / count\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cd4fc820-da1e-40e1-9717-71cdde0a314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "score = get_eval_results(\"faithfulness\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b588b25-20da-441d-a323-02b5d304b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevancy Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "score = get_eval_results(\"relevancy\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f74e05de-94de-49a6-a868-404f9f7ac8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctness Score: 3.90625\n"
     ]
    }
   ],
   "source": [
    "score = get_eval_results(\"correctness\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b84e09f6-8aef-42c4-8ecb-e116eee756c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic Score: 0.8915432709518762\n"
     ]
    }
   ],
   "source": [
    "score = get_eval_results(\"semantic\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5f6be077-e64b-4492-8bbf-a249f934d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: internlm2\n",
      "faithfulness Score: 0.95\n",
      "relevancy Score: 0.85\n",
      "correctness Score: 3.90625\n",
      "semantic Score: 0.8915432709518762\n"
     ]
    }
   ],
   "source": [
    "print(f\"model: {llm.model}\")\n",
    "score_faithfulness = get_eval_results(\"faithfulness\", eval_results)\n",
    "score_relevancy = get_eval_results(\"relevancy\", eval_results)\n",
    "score_correctness = get_eval_results(\"correctness\", eval_results)\n",
    "score_semantic = get_eval_results(\"semantic\", eval_results)\n",
    "\n",
    "# print(f\"score faithfulness: {score_faithfulness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0dc2fe7b-e0a2-4339-a8b7-ead32c0ed21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvaluationResult(query='What are some traditional application domains where deep learning has been successfully applied?', contexts=['This is the strong point of deep learning against \\ntraditional machine learning approaches. The following table \\nshows the different feature -based  learn ing approaches with \\ndifferent learning steps.   \\n       \\nFig. 3.  Where to apply DL approaches  \\nC. When and where to apply DL  \\nDL is employed in several situations where machine \\nintelligence would be useful (see Fig. 3): \\n1. Absence of a human expert (navigation on  Mars)  \\n2. Human s are unable to explain their expertise (speech \\nrecognition, vision and language understanding)  \\n3. The solution to the problem changes over time (tracking, \\nweather prediction, preference, stock, price prediction)  \\n4. Solutions need to be adapted to the particular case s \\n(biometrics, personalization) . \\n5. The problem size is too vast for our limited reasoning \\ncapabilities (calculation webpage ranks, matching ads to \\nFacebook, sentiment analysis).   \\n \\nAt present deep learning is being applied in almost all areas. As \\na result, this approach is often called a universal learning \\napproach. Some example applications are shown in Fig. 4.  \\n \\n            \\n               Object localization                                       Object detection  \\n \\n      \\n           Image or Video Captioning                         Media and entertainment        \\n    \\n                \\n      Image or video Segmentation                          Autonomous Car  \\n \\n                      \\n             Machine translation                                   Speech recognition  \\n \\n                      \\nSecurity and Defense                              Medicine and biology                    \\n                       Brian Cancer Detection                                Skin cancer recognition                \\nFig. 4. Example images where DL is applied successfully and achieved state-\\nof-the-art performance . \\nD. State -of-the-art performance of DL  \\nThere are some outstanding successes in the fields of computer \\nvision and speech recognition as discussed below:', 'One example s is the  GAN , which is an outstanding \\napproach for data generation for any task which can generate \\ndata with the same distribution [28]. Fourthly, multi -task and  \\ntransfer learning which we have discussed in Section 7. \\nFourthly, there is a lot of research  that has been conducted on \\nenergy efficient deep learning approaches with respect to \\nnetwork architectures and hardwires. Section 10 discusses this  \\nissue  \\nCan we m ake any uniform model that can solve multiple tasks \\nin different application domain s? As far as the multi -model \\nsystem is concern ed, there has been one paper published   \\nrecently from Google titled “One Model To Learn Them All” \\n[29]. This approach can lear n from different application \\ndomain s including ImageNet, multiple translation tasks, Image \\ncaptioning (MS -COCO dataset), speech recognition corpus and \\nEnglish parsing task. We will be discussing most of the \\nchallenges and respective solution s through this survey. There are some other multi -task techniques that have been proposed \\nin the last few years [30, 31, and 32]  \\n \\nFig. 7.  The performance of deep learning with respect to the number of data.  \\n \\nFinally, a learning system with causality has been presented, \\nwhich is a graphical model that define s how one may infer a \\ncausal model from data. Recently a DL based approach has \\nbeen proposed for solving this type of problem [33]. However, \\nthere are other many challenging issues have been solved in the \\nlast few year s which were not possible to solve efficiently \\nbefore this revolution. For example: image or video captioning \\n[34], style transferring from one domain to anther domain using \\nGAN [35], text to image synthesis [36], and many more [37].  \\nThere are some survey s that have been conducted recently in \\nthis field [ 294,295] . These papers survey on deep learning and \\nits revolution , but this they did not address the recently \\ndeveloped generative model called GAN [28].'], response=\"Deep learning applications have transcended conventional boundaries in various fields. Here's a concise list of some significant areas:\\n\\n1. **Computer Vision**:\\n   - Object localization and detection.\\n   - Image or video captioning.\\n\\n2. **Multimedia Entertainment**: \\n   - Media processing, including generating content like images from text (text-to-image synthesis).\\n\\n3. **Autonomous Vehicles**: \\n   - Vehicle segmentation in autonomous cars to enhance safety features such as collision avoidance systems.\\n\\n4. **Language Processing and Natural Language Understanding**:\\n   - Machine translation.\\n   - Speech recognition tasks involving voice-based commands or interaction with AI assistants like Siri, Alexa etc.\\n\\n5. **Healthcare and Medicine**: \\n   - Brian cancer detection using medical imaging data analysis techniques powered by deep learning models such as CNNs (Convolutional Neural Networks).\\n   - Skin cancer recognition from dermatologist images.\\n\\n6. **Advertising Technology**:\\n   - Matching ads to Facebook users based on their engagement patterns, interests etc., enhancing personalization and ad relevance in real-time.\\n   \\n7. **Search Engine Optimization**: \\n   - Rank calculation webpage ranks by understanding the contextual information present within web content using deep learning models.\\n\\n8. **Marketplace Recommendation Systems**:\\n   - Personalized recommendations like those offered on Amazon or Netflix, which use user preference data to suggest products.\\n\\nThese are just a few examples where deep learning techniques have achieved state-of-the-art performance and significantly improved the capabilities in various application domains.\\n\", passing=True, feedback='YES', score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"faithfulness\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "876927e2-3ec6-46e3-8e54-96d1f9b14061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvaluationResult(query='What are some traditional application domains where deep learning has been successfully applied?', contexts=['This is the strong point of deep learning against \\ntraditional machine learning approaches. The following table \\nshows the different feature -based  learn ing approaches with \\ndifferent learning steps.   \\n       \\nFig. 3.  Where to apply DL approaches  \\nC. When and where to apply DL  \\nDL is employed in several situations where machine \\nintelligence would be useful (see Fig. 3): \\n1. Absence of a human expert (navigation on  Mars)  \\n2. Human s are unable to explain their expertise (speech \\nrecognition, vision and language understanding)  \\n3. The solution to the problem changes over time (tracking, \\nweather prediction, preference, stock, price prediction)  \\n4. Solutions need to be adapted to the particular case s \\n(biometrics, personalization) . \\n5. The problem size is too vast for our limited reasoning \\ncapabilities (calculation webpage ranks, matching ads to \\nFacebook, sentiment analysis).   \\n \\nAt present deep learning is being applied in almost all areas. As \\na result, this approach is often called a universal learning \\napproach. Some example applications are shown in Fig. 4.  \\n \\n            \\n               Object localization                                       Object detection  \\n \\n      \\n           Image or Video Captioning                         Media and entertainment        \\n    \\n                \\n      Image or video Segmentation                          Autonomous Car  \\n \\n                      \\n             Machine translation                                   Speech recognition  \\n \\n                      \\nSecurity and Defense                              Medicine and biology                    \\n                       Brian Cancer Detection                                Skin cancer recognition                \\nFig. 4. Example images where DL is applied successfully and achieved state-\\nof-the-art performance . \\nD. State -of-the-art performance of DL  \\nThere are some outstanding successes in the fields of computer \\nvision and speech recognition as discussed below:', 'One example s is the  GAN , which is an outstanding \\napproach for data generation for any task which can generate \\ndata with the same distribution [28]. Fourthly, multi -task and  \\ntransfer learning which we have discussed in Section 7. \\nFourthly, there is a lot of research  that has been conducted on \\nenergy efficient deep learning approaches with respect to \\nnetwork architectures and hardwires. Section 10 discusses this  \\nissue  \\nCan we m ake any uniform model that can solve multiple tasks \\nin different application domain s? As far as the multi -model \\nsystem is concern ed, there has been one paper published   \\nrecently from Google titled “One Model To Learn Them All” \\n[29]. This approach can lear n from different application \\ndomain s including ImageNet, multiple translation tasks, Image \\ncaptioning (MS -COCO dataset), speech recognition corpus and \\nEnglish parsing task. We will be discussing most of the \\nchallenges and respective solution s through this survey. There are some other multi -task techniques that have been proposed \\nin the last few years [30, 31, and 32]  \\n \\nFig. 7.  The performance of deep learning with respect to the number of data.  \\n \\nFinally, a learning system with causality has been presented, \\nwhich is a graphical model that define s how one may infer a \\ncausal model from data. Recently a DL based approach has \\nbeen proposed for solving this type of problem [33]. However, \\nthere are other many challenging issues have been solved in the \\nlast few year s which were not possible to solve efficiently \\nbefore this revolution. For example: image or video captioning \\n[34], style transferring from one domain to anther domain using \\nGAN [35], text to image synthesis [36], and many more [37].  \\nThere are some survey s that have been conducted recently in \\nthis field [ 294,295] . These papers survey on deep learning and \\nits revolution , but this they did not address the recently \\ndeveloped generative model called GAN [28].'], response=\"Deep learning applications have transcended conventional boundaries in various fields. Here's a concise list of some significant areas:\\n\\n1. **Computer Vision**:\\n   - Object localization and detection.\\n   - Image or video captioning.\\n\\n2. **Multimedia Entertainment**: \\n   - Media processing, including generating content like images from text (text-to-image synthesis).\\n\\n3. **Autonomous Vehicles**: \\n   - Vehicle segmentation in autonomous cars to enhance safety features such as collision avoidance systems.\\n\\n4. **Language Processing and Natural Language Understanding**:\\n   - Machine translation.\\n   - Speech recognition tasks involving voice-based commands or interaction with AI assistants like Siri, Alexa etc.\\n\\n5. **Healthcare and Medicine**: \\n   - Brian cancer detection using medical imaging data analysis techniques powered by deep learning models such as CNNs (Convolutional Neural Networks).\\n   - Skin cancer recognition from dermatologist images.\\n\\n6. **Advertising Technology**:\\n   - Matching ads to Facebook users based on their engagement patterns, interests etc., enhancing personalization and ad relevance in real-time.\\n   \\n7. **Search Engine Optimization**: \\n   - Rank calculation webpage ranks by understanding the contextual information present within web content using deep learning models.\\n\\n8. **Marketplace Recommendation Systems**:\\n   - Personalized recommendations like those offered on Amazon or Netflix, which use user preference data to suggest products.\\n\\nThese are just a few examples where deep learning techniques have achieved state-of-the-art performance and significantly improved the capabilities in various application domains.\\n\", passing=True, feedback='YES', score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"relevancy\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "96e8f924-9e46-4b80-b4c1-3c352209567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvaluationResult(query='What are some traditional application domains where deep learning has been successfully applied?', contexts=None, response=\"Deep learning applications have transcended conventional boundaries in various fields. Here's a concise list of some significant areas:\\n\\n1. **Computer Vision**:\\n   - Object localization and detection.\\n   - Image or video captioning.\\n\\n2. **Multimedia Entertainment**: \\n   - Media processing, including generating content like images from text (text-to-image synthesis).\\n\\n3. **Autonomous Vehicles**: \\n   - Vehicle segmentation in autonomous cars to enhance safety features such as collision avoidance systems.\\n\\n4. **Language Processing and Natural Language Understanding**:\\n   - Machine translation.\\n   - Speech recognition tasks involving voice-based commands or interaction with AI assistants like Siri, Alexa etc.\\n\\n5. **Healthcare and Medicine**: \\n   - Brian cancer detection using medical imaging data analysis techniques powered by deep learning models such as CNNs (Convolutional Neural Networks).\\n   - Skin cancer recognition from dermatologist images.\\n\\n6. **Advertising Technology**:\\n   - Matching ads to Facebook users based on their engagement patterns, interests etc., enhancing personalization and ad relevance in real-time.\\n   \\n7. **Search Engine Optimization**: \\n   - Rank calculation webpage ranks by understanding the contextual information present within web content using deep learning models.\\n\\n8. **Marketplace Recommendation Systems**:\\n   - Personalized recommendations like those offered on Amazon or Netflix, which use user preference data to suggest products.\\n\\nThese are just a few examples where deep learning techniques have achieved state-of-the-art performance and significantly improved the capabilities in various application domains.\\n\", passing=True, feedback='The generated answer provides a relevant and detailed list of traditional application domains where deep learning has been successfully applied. It covers areas such as computer vision, multimedia entertainment, autonomous vehicles, language processing, healthcare, advertising technology, search engine optimization, and marketplace recommendation systems. The answer is comprehensive and accurate, aligning well with the user query. However, it lacks some domains mentioned in the reference answer, such as art, bio-informatics, and cybersecurity, which prevents it from receiving a perfect score.', score=4.0, pairwise_source=None, invalid_result=False, invalid_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"correctness\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "252d1548-74db-4d1e-bc2a-e05f5b77145c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvaluationResult(query=None, contexts=None, response=None, passing=True, feedback='Similarity score: 0.9386481964361731', score=0.9386481964361731, pairwise_source=None, invalid_result=False, invalid_reason=None)]\n"
     ]
    }
   ],
   "source": [
    "print(eval_results[\"semantic\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876cabe1-3c56-4cd9-8da6-b051537a660a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b378de-c3af-4e8d-9b43-9b110efaa550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af3f2e-4bf5-4acb-8d7c-0e2289aaecb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a478b-b060-4288-b479-dba8fa694680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bc6dc-7a82-48a9-94f5-da7b0d906da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
